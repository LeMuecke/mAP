<!Doctype html>
<html>
<style>
.btn-group button {
  background-color: #4CAF50; /* Green background */
  border: 1px solid green; /* Green border */
  color: white; /* White text */
  padding: 10px 24px; /* Some padding */
  cursor: pointer; /* Pointer/hand icon */
  float: left; /* Float the buttons side by side */
}

/* Clear floats (clearfix hack) */
.btn-group:after {
  content: "";
  clear: both;
  display: table;
}

.btn-group button:not(:last-child) {
  border-right: none; /* Prevent double borders */
}

/* Add a background color on hover */
.btn-group button:hover {
  background-color: #3e8e41;
}

.btn-group button:active {
  background: #e5e5e5;
  -webkit-box-shadow: inset 0px 0px 5px #c1c1c1;
     -moz-box-shadow: inset 0px 0px 5px #c1c1c1;
          box-shadow: inset 0px 0px 5px #c1c1c1;
   outline: none;
}
</style>
<body>

<div class="btn-group" style="width:100%">
  <button style="width:50%" onclick="show_text(this)" id="AlexeyAB">AlexeyAB/darknet</button>
  <button style="width:50%" onclick="show_text(this)" id="Darkflow">Darkflow</button>
  <button style="width:50%" onclick="show_text(this)" id="PASCAL" >PASCAL VOC</button>
  <button style="width:50%" onclick="show_text(this)" id="pjreddie">pjreddie/darknet</button>
  <button style="width:50%" onclick="show_text(this)" id="Keras">Keras-yolo3</button>
  <button style="width:50%" onclick="show_text(this)" id="Other">Other</button>
</div>

<div id="AlexeyAB_text" style="display:none">
  <p>Step-by-step:</p>
  <ol>
    <li>Edit the file <code>class.names</code> in the directory <code>mAP/input/</code> to your own set of classes (one per line)</li>
    <li>Create the <code>ground-truth</code> files (<a href="#AlexeyAB_step_2">explained below</a>)</li>
    <li>Copy the <code>ground-truth</code> files (one per image) to the directory <code>mAP/input/ground-truth/</code></li>
    <li>Create the <code>results.txt</code> file (<a href="#AlexeyAB_step_4">explained below</a>)</li>
    <li>Copy the <code>resuts.txt</code> file to the directory <code>mAP/input/detection-results/</code></li>
    <li>(optional) Copy the relevant images to the directory <code>mAP/input/images-optional/</code></li>
    <li>Run the code: <code>python main.py</code></li>
  </ol>
  <h5 id="AlexeyAB_step_2">2. Create the ground-truth files</h5>
  <p>The AlexeyAB's training/test files are already in the YOLO format (one of the formats that we support). So you can just jump to step 3. Additionally, if you need to label a new set of pictures in the YOLO format you can use this tool in Python: <a href="https://github.com/Cartucho/OpenLabeling">OpenLabeling</a>.</p>
  <h5 id="AlexeyAB_step_4">4. Create the results.txt file</h5>
  <p>As explained in the <a href="https://github.com/AlexeyAB/darknet#how-to-use-on-the-command-line">AlexeyAB repo's README</a> you can run the detector on a set of images and save the detection-results to a single <code>result.txt</code> file. An example is shown below:</p>
  <pre>
  <code>
# Example: forward all images in data/train.txt using yolov3 coco and output to the file result.txt
darknet.exe detector test cfg/coco.data yolov3.cfg yolov3.weights -dont_show -ext_output &lt; data/train.txt &gt; result.txt</code>
  </pre>
</div>

<div id="Darkflow_text" style="display:none">
  <p>Step-by-step:</p>
  <ol>
    <li>Create the <code>ground-truth</code> files (<a href="#Darkflow_step_1">explained below</a>)</li>
    <li>Copy the <code>ground-truth</code> files (one per image) to the directory <code>mAP/input/ground-truth/</code></li>
    <li>Create the <code>detection-results</code> JSON files (<a href="#Darkflow_step_3">explained below</a>)</li>
    <li>Copy the JSON files (one per image) to the directory <code>mAP/input/detection-results/</code></li>
    <li>(optional) Copy the relevant images to the directory <code>mAP/input/images-optional/</code></li>
    <li>Run the code: <code>python main.py</code></li>
  </ol>
  <h5 id="Darkflow_step_1">1. Create the ground-truth files</h5>
  <p>The Darkflow training/test files are already in the PASCAL VOC format (one of the formats that we support). So you can just jump to step 2. Additionally, if you need to label a new set of pictures in the PASCAL VOC format you can use this tool in Python: <a href="https://github.com/Cartucho/OpenLabeling">OpenLabeling</a>.</p>
  <h5 id="Darkflow_step_3">3. Create the detection-results JSON files</h5>
  <p>As explained in the Darkflow repo's README you can run the detector on a set of images and save the detection-results to multiple JSON files (one of the formats that we support). So you can just jump to step 4 after running a command like:</p>
  <pre>
    <code>
    # Example: forward all images in sample_img/ using tiny yolo and JSON output
    flow --imgdir sample_img/ --model cfg/tiny-yolo.cfg --load bin/tiny-yolo.weights --json
    </code>
  </pre>
</div>

<div id="PASCAL_text" style="display:none">
  <p>Step-by-step:</p>
  <ol>
    <li>Create the <code>ground-truth</code> files (<a href="#PASCAL_step_1">explained below</a>)</li>
    <li>Copy the <code>ground-truth</code> files (one per image) to the directory <code>mAP/input/ground-truth/</code></li>
    <li>Create the <code>detection-results</code> files (<a href="#PASCAL_step_3">explained below</a>)</li>
    <li>Copy the <code>detection-results</code> files (one per image) to the directory <code>mAP/input/detection-results/</code></li>
    <li>(optional) Copy the relevant images to the directory <code>mAP/input/images-optional/</code></li>
    <li>Run the code: <code>python main.py</code></li>
  </ol>
  <p>To run the code you must have one (1) <code>ground-truth</code> and one (1) <code>detection-results</code> file for each picture. These files must all have the same basename when without the extension (<code>.jpg</code>, <code>.txt</code>). For example <code>ground-truth/image_1.txt</code>, <code>detection-results/image_1.txt</code>, <code>image-optional/image_1.jpg</code> all share the same basename <code>image_1</code>.</p>
  <h5 id="PASCAL_step_1">1. Create the ground-truth files</h5>
  <p>The PASCAL VOC format is one of the formats that we support. So you can just jump to step 2. Additionally, if you need to label a new set of pictures in the PASCAL VOC format you can use this tool in Python: <a href="https://github.com/Cartucho/OpenLabeling">OpenLabeling</a>.</p>
  <h5 id="PASCAL_step_3">3. Create the detection-results files</h5>
  <p>The <code>detection-results</code> files can also be in the PASCAL VOC format.</p>
</div>

<div id="pjreddie_text" style="display:none">
  <p>Step-by-step:</p>
  <ol>
    <li>Edit the file <code>class.names</code> in the directory <code>mAP/input/</code> to your own set of classes (one per line)</li>
    <li>Create the <code>ground-truth</code> files (<a href="#pjreddie_step_2">explained below</a>)</li>
    <li>Copy the <code>ground-truth</code> files (one per image) to the directory <code>mAP/input/ground-truth/</code></li>
    <li>Create the <code>detection-results</code> files (<a href="#pjreddie_step_4">explained below</a>)</li>
    <li>Copy the <code>detection-results</code> files (one per image) to the directory <code>mAP/input/detection-results/</code></li>
    <li>(optional) Copy the relevant images to the directory <code>mAP/input/images-optional/</code></li>
    <li>Run the code: <code>python main.py</code></li>
  </ol>
  <h5 id="pjreddie_step_2">2. Create the ground-truth files</h5>
  <p>The pjreddie's training/test files are already in the YOLO format (one of the formats that we support). So you can just jump to step 3. Additionally, if you need to label a new set of pictures in the YOLO format you can use this tool in Python: <a href="https://github.com/Cartucho/OpenLabeling">OpenLabeling</a>.</p>
  <h5 id="pjreddie_step_4">4. Create the detection-results files</h5>
  <p>To store the <code>detection-results</code> files just copy the file <code>save_darknet_detection_results.py</code> in the directory <code>mAP/scripts/create_input_files/</code> to the <code>pjreddie/darknet/python</code> directory.</p>
  <p>Then just run that script inside the <code>pjreddie/darknet</code> directory:</p>
  <pre>
    <code>
    # Example: forward all images in data/image_folder/ using YOLOv2_VOC (you can also specify the --output folder, by default it will be darknet/results/)
    python python/save_darknet_detection_results.py --cfg 'cfg/yolov2-voc.cfg' --weights 'yolov2-voc.weights' --data 'cfg/voc.data' --input_dir data/image_folder
    </code>
  </pre>
</div>

<div id="Keras_text" style="display:none">
  <p>Keras. TODO! If you are using Keras please start a issue on GitHub mAP and ask for adding support to this version and we will add this format! (:</p>
</div>

<div id="Other_text" style="display:none">
  <p>To run the code you must have one (1) <code>ground-truth</code> and one (1) <code>detection-results</code> file for each picture. These files must all have the same basename when without the extension (<code>.jpg</code>, <code>.txt</code>). For example <code>ground-truth/image_1.txt</code>, <code>detection-results/image_1.txt</code>, <code>image-optional/image_1.jpg</code> all share the same basename <code>image_1</code>.</p>
  <p>The <code>ground-truth</code> and the <code>detection-results</code> files can be in multiple formats. Here we will explain one of them (the YOLO format) in detail. In the YOLO format, inside each <code>.txt</code> file there is one line for each object in an image.</p>
  <p>Step-by-step:</p>
  <ol>
    <li>Edit the file <code>class.names</code> in the directory <code>mAP/input/</code> to your own set of classes (one per line)</li>
    <li>Create the <code>ground-truth</code> files (<a href="#Other_step_2">explained below</a>)</li>
    <li>Copy the <code>ground-truth</code> files (one per image) to the directory <code>mAP/input/ground-truth/</code></li>
    <li>Create the <code>detection-results</code> files (<a href="#Other_step_4">explained below</a>)</li>
    <li>Copy the <code>detection-results</code> files (one per image) to the directory <code>mAP/input/detection-results/</code></li>
    <li>(optional) Copy the relevant images to the directory <code>mAP/input/images-optional/</code></li>
    <li>Run the code: <code>python main.py</code></li>
  </ol>
  <h5 id="Other_step_2">2. Create the ground-truth files</h5>
  <p>Darknet YOLO wants a .txt file for each image with a line for each ground-truth object in the image that looks like:</p>
  <pre><code>&lt;class_index&gt; &lt;x_center&gt; &lt;y_center&gt; &lt;width&gt; &lt;height&gt;</code></pre>
  <p>, where <code>&lt;class_index&gt;</code> corresponds to index of the object's class from <code>0</code> to <code>#classes - 1</code> (remember that you first need to edit the file <code>input/class.names</code> to your own set of classes). The other values  <code>&lt;x_center&gt; &lt;y_center&gt; &lt;width&gt; &lt;height&gt;</code> correspond to the bounding box of each object. These dimensions are calculated relatively to the width and height of the image, so note that the values can range between 0 and 1.0. Also note that <code>&lt;x_center&gt; &lt;y_center&gt;</code> are the center of the bounding-box and not the top-left corner.</p>
  <p>If you need a tool to create the ground-truth you can use <a href="https://github.com/Cartucho/OpenLabeling">OpenLabeling</a>.</p>
  <p>E.g. <code>ground-truth/image_1.txt</code>:</p>
  <pre><code>
19 0.504222905636 0.575432434082 0.376204467773 0.267504302979
0  0.402410387993 0.424330688477 0.386157307943 0.353413604736
1  0.413456357572 0.575212434082 0.376204467773 0.313203102979
  </code></pre>
  <h5 id="Other_step_4">4. Create the detection-results files</h5>
  <p>The <code>detection-results</code> files have 1 (one) additional parameter when compared to the <code>ground-truth</code> files: the <code>&lt;confidence&gt;</code> score. This value represents the confidence score for each of the detected objects, so note that the values can range between 0 and 1.0.</p>
  <pre><code>&lt;class-index&gt; &lt;confidence&gt; &lt;x_center&gt; &lt;y_center&gt; &lt;width&gt; &lt;height&gt;</code></pre>
  <p>E.g. <code>detection-results/image_1.txt</code>:</p>
  <pre><code>
14 0.872790455818 0.325253814697 0.490553100586 0.421687042236 0.819358723958
14 0.869335949421 0.499317230225 0.532302449544 0.2415572052 0.636518513997
  </code></pre>
</div>


<script>
function show_text(ele) {
  var id_selected = ele.id;
  var str = "_text";
  var id_selected_text = id_selected.concat(str)

  var ids = ["AlexeyAB_text", "Darkflow_text", "PASCAL_text", "pjreddie_text", "Keras_text", "Other_text"];
  ids.forEach(function(id_temp) {
    document.getElementById(id_temp).style.display = "none";
  });

  document.getElementById(id_selected_text).style.display = "block";
}
</script>
</body>
</html>
